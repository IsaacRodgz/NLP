{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from scipy import sparse\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "\n",
    "    # Training set\n",
    "    with open('mex20_train.txt', 'r') as f:\n",
    "        corpus_train = f.readlines()\n",
    "    with open('mex20_train_labels.txt', 'r') as f:\n",
    "        labels_train = f.readlines()\n",
    "    labels_train = [int(lab.strip('\\n')) for lab in labels_train]\n",
    "    tweets_train = [tw.strip('\\n') for tw in corpus_train]\n",
    "\n",
    "    # Validation set\n",
    "    with open('mex20_val.txt', 'r') as f:\n",
    "        corpus_val = f.readlines()\n",
    "    with open('mex20_val_labels.txt', 'r') as f:\n",
    "        labels_val = f.readlines()\n",
    "    labels_val = [int(lab.strip('\\n')) for lab in labels_val]\n",
    "    tweets_val = [tw.strip('\\n') for tw in corpus_val]\n",
    "\n",
    "    # Test set\n",
    "    with open('mex20_test_full.txt', 'r') as f:\n",
    "        corpus_test = f.readlines()\n",
    "    tweets_test = [tw.strip('\\n') for tw in corpus_test]\n",
    "\n",
    "    return tweets_train, labels_train, tweets_val, labels_val, tweets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5278 for training\n",
      "587 for validation\n",
      "1467 for test\n"
     ]
    }
   ],
   "source": [
    "X_train_, y_train, X_val_, y_val, X_test_ = read_data()\n",
    "print(\"{0} for training\\n{1} for validation\\n{2} for test\".format(len(X_train_), len(X_val_), len(X_test_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        #self.wnl = WordNetLemmatizer()\n",
    "        self.tt = TweetTokenizer()\n",
    "        self.punct = set(['.', ',', ';', ':', '-', '!', '¬°', '¬ø', '?', '\"', '\\'',\n",
    "             '...', '‚Ä¶', 'Ô∏è', '(', ')', '<url>', '*', '@usuario',\n",
    "            '‚Äú', '‚Äù', '..', '/'])\n",
    "\n",
    "    def process_word(self, word):\n",
    "        w = word.lower()\n",
    "        w = w.strip('#')\n",
    "        is_punct = True if w in self.punct or '@' in w else False\n",
    "        is_digit = w.isnumeric()\n",
    "        is_stopword = w in stopwords.words('spanish')\n",
    "\n",
    "        return \"\" if is_punct or is_digit else w\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        return list(filter(None, [self.process_word(t) for t in self.tt.tokenize(doc)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = 'word', ngram_range = (1,3), min_df = 2, max_df = 1000)\n",
    "#tokenizer = LemmaTokenizer()\n",
    "X_train = vectorizer.fit_transform(X_train_)\n",
    "X_val = vectorizer.transform(X_val_)\n",
    "X_test = vectorizer.transform(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.build_analyzer()(\"Anden putos, recuerdan el #noerapenal #Holanda fuera de #Rusia2018, esto se llama #karma ehhhhhhhh #puuuuuutos Soy mam√° soltera luchona &amp; patriota! Jajaja ‚ô•Ô∏èüá≤üáΩüéâüòç‚ò∫Ô∏è #LosAmoInfinito <URL> @USUARIO?? :v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = 'char', ngram_range = (3,6), min_df = 3, max_df = 1000)\n",
    "X_train2 = vectorizer.fit_transform(X_train_)\n",
    "X_val2 = vectorizer.transform(X_val_)\n",
    "X_test2 = vectorizer.transform(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = preprocessing.normalize(X_train2, norm='l2')\n",
    "X_val2 = preprocessing.normalize(X_val2, norm='l2')\n",
    "X_test2 = preprocessing.normalize(X_test2, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5278, 5000)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5278, 74799)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = svm.LinearSVC(C=0.05, penalty=\"l1\", dual=False).fit(X_train, y_train)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_train = model.transform(X_train)\n",
    "X_val = model.transform(X_val)\n",
    "X_test = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = SelectKBest(chi2, k=5000)\n",
    "select.fit(X_train, y_train)\n",
    "X_train = select.transform(X_train)\n",
    "X_val = select.transform(X_val)\n",
    "X_test = select.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = SelectKBest(chi2, k=4500)\n",
    "select.fit(X_train2, y_train)\n",
    "X_train2 = select.transform(X_train2)\n",
    "X_val2 = select.transform(X_val2)\n",
    "X_test2 = select.transform(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sparse.vstack([X_train, X_val])\n",
    "y_train = y_train+y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sparse.vstack([X_train_concat, X_val_concat])\n",
    "y_train = y_train+y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_concat = sp.sparse.hstack([X_train, X_train2])\n",
    "X_val_concat = sp.sparse.hstack([X_val, X_val2])\n",
    "X_test_concat = sp.sparse.hstack([X_test, X_test2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recurso de emociones CANADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emo_vect_tfidf_norm(tweets, emotions_dict):\n",
    "    \n",
    "    words_emo = []\n",
    "\n",
    "    for tweet in tweets:\n",
    "\n",
    "        tweet_vect = np.zeros(len(emotions_dict.iloc[0]))\n",
    "\n",
    "        # Transforma cada tweet a su vector de emociones\n",
    "        for word in tweet.split():\n",
    "\n",
    "            # Se verifica si la palabra est√° incluida en el diccionario de emociones\n",
    "            try:\n",
    "                if len(emotions_dict.loc[word]) == 1:\n",
    "                    w_vect = np.array(emotions_dict.loc[word])\n",
    "                else:\n",
    "                    w_vect = np.array(emotions_dict.loc[word].sum(axis = 0, skipna = True))\n",
    "                tweet_vect += np.array(w_vect)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        words_emo.append(tweet_vect)\n",
    "\n",
    "    words_emo = np.array(words_emo)\n",
    "        \n",
    "    for i in range(words_emo.shape[0]):\n",
    "        emotions_index = np.nonzero(words_emo[i])[0]\n",
    "        for j in emotions_index:\n",
    "            num_tweets = len(np.nonzero(words_emo[:, j])[0])\n",
    "            words_emo[i][j] = words_emo[i][j]*np.log10((words_emo.shape[0]/num_tweets) + 1)\n",
    "            \n",
    "    for i in range(words_emo.shape[0]):\n",
    "        norm = np.linalg.norm(words_emo[i])\n",
    "\n",
    "        if norm == 0:\n",
    "            norm = 1\n",
    "\n",
    "        words_emo[i] = words_emo[i]/norm\n",
    "\n",
    "    return words_emo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_dict = pd.read_csv(\"emolex.csv\")\n",
    "emotions_dict = emotions_dict.set_index('Spanish (es)')\n",
    "\n",
    "BOW_train_emo=emo_vect_tfidf_norm(X_train_, emotions_dict)\n",
    "BOW_val_emo=emo_vect_tfidf_norm(X_val_, emotions_dict)\n",
    "BOW_test_emo=emo_vect_tfidf_norm(X_test_, emotions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_concat = sp.sparse.hstack([X_train, BOW_train_emo])\n",
    "X_val_concat = sp.sparse.hstack([X_val, BOW_val_emo])\n",
    "X_test_concat = sp.sparse.hstack([X_test, BOW_test_emo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_concat = sp.sparse.hstack([X_train, X_train2, BOW_train_emo])\n",
    "X_val_concat = sp.sparse.hstack([X_val, X_val2, BOW_val_emo])\n",
    "X_test_concat = sp.sparse.hstack([X_test, X_test2, BOW_test_emo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recurso emociones SEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emo_vect_sel_tfidf_norm(tweets, emotions_dict):\n",
    "    \n",
    "    words_emo = []\n",
    "    emo_list = list(sel_emotions_dict.Categor√≠a.unique())\n",
    "    num_cols = len(emo_list)\n",
    "\n",
    "    for tweet in tweets:\n",
    "\n",
    "        tweet_vect = np.zeros(len(emotions_dict.iloc[0]))\n",
    "\n",
    "        # Transforma cada tweet a su vector de emociones\n",
    "        for word in tweet.split():\n",
    "\n",
    "             # Se verifica si la palabra est√° incluida en el diccionario de emociones\n",
    "            try:\n",
    "                if len(emotions_dict.loc[word]) == 1:\n",
    "                    w_vect = np.array(sel_emotions_dict.loc[word][:-1], dtype=np.float)\n",
    "                else:\n",
    "                    w_vect = np.array(emotions_dict.loc[word][:-1].sum(axis = 0, skipna = True), dtype=np.float)\n",
    "\n",
    "                tweet_vect += w_vect\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        words_emo.append(tweet_vect)\n",
    "\n",
    "    words_emo = np.array(words_emo)\n",
    "        \n",
    "    for i in range(words_emo.shape[0]):\n",
    "        emotions_index = np.nonzero(words_emo[i])[0]\n",
    "        for j in emotions_index:\n",
    "            num_tweets = len(np.nonzero(words_emo[:, j])[0])\n",
    "            words_emo[i][j] = words_emo[i][j]*np.log10((words_emo.shape[0]/num_tweets) + 1)\n",
    "            \n",
    "    for i in range(words_emo.shape[0]):\n",
    "        norm = np.linalg.norm(words_emo[i])\n",
    "\n",
    "        if norm == 0:\n",
    "            norm = 1\n",
    "\n",
    "        words_emo[i] = words_emo[i]/norm\n",
    "\n",
    "    return words_emo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_emotions_dict = pd.read_csv(\"SEL_full.txt\", sep='\\t', encoding = \"ISO-8859-1\")\n",
    "sel_emotions_dict = sel_emotions_dict.set_index('Palabra')\n",
    "\n",
    "BOW_train_emo_sel=emo_vect_sel_tfidf_norm(X_train_, sel_emotions_dict)\n",
    "BOW_val_emo_sel=emo_vect_sel_tfidf_norm(X_val_, sel_emotions_dict)\n",
    "BOW_test_emo_sel=emo_vect_sel_tfidf_norm(X_test_, sel_emotions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_concat = sp.sparse.hstack([X_train, BOW_train_emo_sel])\n",
    "X_val_concat = sp.sparse.hstack([X_val, BOW_val_emo_sel])\n",
    "X_test_concat = sp.sparse.hstack([X_test, BOW_test_emo_sel])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'alpha': [0.0001, 0.0003, 0.0009, 0.001, 0.01]}\n",
    "svr = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', learning_rate_init=0.001)\n",
    "grid = GridSearchCV(estimator=svr, param_grid=parameters, n_jobs=8, scoring=\"f1_macro\", cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C': [.01, .05, 0.8, 0.1, .12, .15, .20, .25]}\n",
    "svr = svm.LinearSVC(class_weight='balanced')\n",
    "grid = GridSearchCV(estimator=svr, param_grid=parameters, n_jobs=8, scoring=\"f1_macro\", cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C': [.05, .1, .25, 1., 2., 3.5, 4., 8., 10.], 'gamma': [0.01,  0.05, 0.1, 0.5, 1.]}\n",
    "svr = SVC()\n",
    "grid = GridSearchCV(estimator=svr, param_grid=parameters, n_jobs=8, scoring=\"f1_macro\", cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  19 out of  25 | elapsed:  8.9min remaining:  2.8min\n",
      "[Parallel(n_jobs=8)]: Done  25 out of  25 | elapsed: 10.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                     batch_size='auto', beta_1=0.9,\n",
       "                                     beta_2=0.999, early_stopping=False,\n",
       "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
       "                                     learning_rate='constant',\n",
       "                                     learning_rate_init=0.001, max_iter=200,\n",
       "                                     momentum=0.9, n_iter_no_change=10,\n",
       "                                     nesterovs_momentum=True, power_t=0.5,\n",
       "                                     random_state=None, shuffle=True,\n",
       "                                     solver='adam', tol=0.0001,\n",
       "                                     validation_fraction=0.1, verbose=False,\n",
       "                                     warm_start=False),\n",
       "             iid='warn', n_jobs=8,\n",
       "             param_grid={'alpha': [0.0001, 0.0003, 0.0009, 0.001, 0.01]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_macro', verbose=3)"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=8)]: Done  40 out of  40 | elapsed:    6.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LinearSVC(C=1.0, class_weight='balanced', dual=True,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=1000,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='warn', n_jobs=8,\n",
       "             param_grid={'C': [0.01, 0.05, 0.8, 0.1, 0.12, 0.15, 0.2, 0.25]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_macro', verbose=3)"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_concat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88       418\n",
      "           1       0.74      0.59      0.65       169\n",
      "\n",
      "    accuracy                           0.82       587\n",
      "   macro avg       0.79      0.75      0.77       587\n",
      "weighted avg       0.81      0.82      0.81       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(X_val)\n",
    "print(metrics.classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       418\n",
      "           1       0.78      0.73      0.76       169\n",
      "\n",
      "    accuracy                           0.87       587\n",
      "   macro avg       0.84      0.83      0.83       587\n",
      "weighted avg       0.86      0.87      0.86       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# wordVectorizers: word(1,3) - char(3,6)\n",
    "# chi2: word(5000), char(4500)\n",
    "\n",
    "y_pred = grid.predict(X_val_concat)\n",
    "print(metrics.classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       418\n",
      "           1       0.78      0.73      0.76       169\n",
      "\n",
      "    accuracy                           0.87       587\n",
      "   macro avg       0.84      0.83      0.83       587\n",
      "weighted avg       0.86      0.87      0.86       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(X_val_concat)\n",
    "print(metrics.classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svr = SVC(C=4, gamma=0.5)\n",
    "svr.fit(X_train, y_train)\n",
    "y_pred = svr.predict(X_val)\n",
    "print(metrics.classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.05, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = svm.LinearSVC(class_weight='balanced', C=0.05)\n",
    "svr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = grid.predict(X_test_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_pred.txt', 'w') as f:\n",
    "    f.write(\"id,Expected\\n\")\n",
    "    for i in range(len(y_pred_test)):\n",
    "        f.write(\"{0},{1}\\n\".format(i,y_pred_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_scores_val = []\n",
    "f_scores_train = []\n",
    "reg = np.array(np.arange(3.0, 4.5, 0.1))\n",
    "\n",
    "for c in reg:\n",
    "    svr = SVC(C=c, gamma=0.5)\n",
    "    svr.fit(X_train, y_train)\n",
    "    y_pred = svr.predict(X_val)\n",
    "    f_scores_val.append(f1_score(y_val, y_pred, average='macro'))\n",
    "    y_pred = svr.predict(X_train)\n",
    "    f_scores_train.append(f1_score(y_train, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(reg, f_scores_train)\n",
    "plt.plot(reg, f_scores_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import SCORERS\n",
    "sorted(SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = np.array(np.arange(0.001, 0.3, 0.01))\n",
    "train_score, val_score = validation_curve(svm.LinearSVC(class_weight='balanced'), X_train, y_train,\n",
    "                                          param_name=\"C\", param_range=reg, cv=5, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(reg, np.median(train_score, 1), color='blue', label='training score')\n",
    "plt.plot(reg, np.median(val_score, 1), color='red', label='validation score')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments with countVectorizer - ngram word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exp1:\n",
    "\n",
    "* KAGGLE: 0.78802\n",
    "* SVC with C=3.2, gamma=0.06, kernel='rbf'\n",
    "* CountVectorizer with ngram by word(1,3), min_df=8, max_df=1000\n",
    "\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.94      0.90       418\n",
    "           1       0.82      0.63      0.72       169\n",
    "\n",
    "    accuracy                           0.86       587\n",
    "   macro avg       0.84      0.79      0.81       587\n",
    "weighted avg       0.85      0.86      0.85       587\n",
    "\n",
    "\n",
    "Exp2:\n",
    "\n",
    "* SVC with C=3.6, gamma=0.05, kernel='rbf'\n",
    "* CountVectorizer with ngram by word(1,3), min_df=7, max_df=2000\n",
    "\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.94      0.90       418\n",
    "           1       0.82      0.62      0.70       169\n",
    "\n",
    "    accuracy                           0.85       587\n",
    "   macro avg       0.84      0.78      0.80       587\n",
    "weighted avg       0.85      0.85      0.84       587\n",
    "\n",
    "\n",
    "Exp3:\n",
    "\n",
    "* SVC with C=3.4, gamma=0.04, kernel='rbf'\n",
    "* CountVectorizer with ngram by word(1,3), min_df=8, max_df=2000\n",
    "\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.94      0.90       418\n",
    "           1       0.81      0.64      0.72       169\n",
    "\n",
    "    accuracy                           0.85       587\n",
    "   macro avg       0.84      0.79      0.81       587\n",
    "weighted avg       0.85      0.85      0.85       587\n",
    "\n",
    "\n",
    "Exp4:\n",
    "\n",
    "* SVC with C=3.1, gamma=0.04, kernel='rbf'\n",
    "* CountVectorizer with ngram by word(1,3), min_df=10, max_df=2000\n",
    "\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "           0       0.85      0.94      0.90       418\n",
    "           1       0.81      0.60      0.69       169\n",
    "\n",
    "    accuracy                           0.84       587\n",
    "   macro avg       0.83      0.77      0.79       587\n",
    "weighted avg       0.84      0.84      0.84       587\n",
    "\n",
    "\n",
    "Exp5:\n",
    "\n",
    "* SVC with C=2.9, gamma=0.05, kernel='rbf'\n",
    "* CountVectorizer with ngram by word(1,3), min_df=8, max_df=2500\n",
    "\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "           0       0.85      0.95      0.90       418\n",
    "           1       0.83      0.59      0.69       169\n",
    "\n",
    "    accuracy                           0.85       587\n",
    "   macro avg       0.84      0.77      0.79       587\n",
    "weighted avg       0.84      0.85      0.84       587\n",
    "\n",
    "\n",
    "Exp6:\n",
    "\n",
    "* SVC with C=3, gamma=0.05, kernel='rbf'\n",
    "* CountVectorizer with ngram by word(1,3), min_df=10, max_df=2500\n",
    "\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "           0       0.85      0.94      0.89       418\n",
    "           1       0.81      0.58      0.68       169\n",
    "\n",
    "    accuracy                           0.84       587\n",
    "   macro avg       0.83      0.76      0.78       587\n",
    "weighted avg       0.84      0.84      0.83       587"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments with countVectorizer - ngram char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exp1:\n",
    "\n",
    "* SVC with C=3.5, gamma=0.001, kernel='rbf'\n",
    "* CountVectorizer with ngram by char(3,7), min_df=1, max_df=1000\n",
    "\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.90      0.85       397\n",
    "           1       0.78      0.60      0.68       219\n",
    "\n",
    "    accuracy                           0.80       616\n",
    "   macro avg       0.79      0.75      0.77       616\n",
    "weighted avg       0.79      0.80      0.79       616\n",
    "\n",
    "\n",
    "Exp2:\n",
    "\n",
    "* SVC with C=3.5, gamma=0.001, kernel='rbf'\n",
    "* CountVectorizer with ngram by char(4,7), min_df=10, max_df=1000\n",
    "\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.91      0.85       397\n",
    "           1       0.78      0.60      0.68       219\n",
    "\n",
    "    accuracy                           0.80       616\n",
    "   macro avg       0.79      0.75      0.77       616\n",
    "weighted avg       0.80      0.80      0.79       616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments with TfidfVectorizer - ngram word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exp1:\n",
    "\n",
    "* KAGGLE: 0.77525\n",
    "* SVC with C=3.7, gamma=0.5, kernel='rbf'\n",
    "* TfidfVectorizer with ngram by word(1,3), min_df=8, max_df=1000\n",
    "\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "           0       0.88      0.93      0.90       418\n",
    "           1       0.79      0.69      0.73       169\n",
    "\n",
    "    accuracy                           0.86       587\n",
    "   macro avg       0.83      0.81      0.82       587\n",
    "weighted avg       0.85      0.86      0.85       587\n",
    "\n",
    "Exp2:\n",
    "\n",
    "* SVC with C=4, gamma=0.5, kernel='rbf'\n",
    "* TfidfVectorizer with ngram by word(1,3), min_df=10, max_df=2000\n",
    "\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.88      0.86       397\n",
    "           1       0.76      0.69      0.72       219\n",
    "\n",
    "    accuracy                           0.81       616\n",
    "   macro avg       0.80      0.78      0.79       616\n",
    "weighted avg       0.81      0.81      0.81       616\n",
    "\n",
    "Exp3:\n",
    "\n",
    "* SVC with C=3, gamma=0.3, kernel='rbf'\n",
    "* TfidfVectorizer with ngram by word(1,3), min_df=10, max_df=2500\n",
    "\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.94      0.89       418\n",
    "           1       0.80      0.61      0.69       169\n",
    "\n",
    "    accuracy                           0.84       587\n",
    "   macro avg       0.83      0.77      0.79       587\n",
    "weighted avg       0.84      0.84      0.84       587"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments with TfidfVectorizer - ngram char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exp1:\n",
    "\n",
    "* SVC with C=4, gamma=0.3, kernel='rbf'\n",
    "* TfidfVectorizer with ngram by char(4,7), min_df=10, max_df=2000\n",
    "\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.93      0.90       418\n",
    "           1       0.79      0.64      0.71       169\n",
    "\n",
    "    accuracy                           0.85       587\n",
    "   macro avg       0.83      0.79      0.80       587\n",
    "weighted avg       0.84      0.85      0.84       587"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model1:\n",
    "    * Kaggle Score: 0.80729\n",
    "    * LinearSVC (C = 0.05)\n",
    "    * CountVectorizer - word (1, 3)\n",
    "    * (min_df, max_df) = (2, 2000)\n",
    "    * SelectKBest - mutual_info_classif (k = 5000)\n",
    "    \n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "           0       0.90      0.90      0.90       418\n",
    "           1       0.75      0.75      0.75       169\n",
    "\n",
    "    accuracy                           0.85       587\n",
    "   macro avg       0.82      0.82      0.82       587\n",
    "weighted avg       0.85      0.85      0.85       587\n",
    "\n",
    "\n",
    "Model2:\n",
    "    * Kaggle Score: \n",
    "    * LinearSVC (C = 0.05)\n",
    "    * CountVectorizer - word (1, 3)\n",
    "    * (min_df, max_df) = (2, 2000)\n",
    "    * SelectKBest - mutual_info_classif (k = 5000)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOR Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_word(w, punct):\n",
    "    is_punct = True if w in punct else False\n",
    "    is_digit = w.isnumeric()\n",
    "    is_stopword = w in stopwords.words('spanish')\n",
    "\n",
    "    return \"\" if is_punct or is_digit or is_stopword else w.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_ngrams(words, n, sep=\" \"):\n",
    "    if n > 1:\n",
    "        return [tuple(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "    else:\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngrams(tweets, punct, n):\n",
    "    tk = TweetTokenizer()\n",
    "    tokens = [process_word(w, punct) for sent in tweets for w in tk.tokenize(sent)]\n",
    "    tokens = list(filter(None, tokens))\n",
    "    tw_grams = words_to_ngrams(tokens, n)\n",
    "    tw_grams = FreqDist(tw_grams)\n",
    "    \n",
    "    return tw_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortFreqDict(freqdict):\n",
    "    aux = [(freqdict[key], key) for key in freqdict]\n",
    "    aux.sort()\n",
    "    aux.reverse()\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = set(['.', ',', ';', ':', '-', '!', '¬°', '¬ø', '?', '\"', '\\'',\n",
    "             '...', '‚Ä¶', 'Ô∏è', '(', ')', '<url>', '*', '@usuario',\n",
    "            '‚Äú', '‚Äù', '..', '/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = build_ngrams(X_train, punct, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = sortFreqDict(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = V[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_indices = dict()\n",
    "cont = 0\n",
    "for weight, word in V:\n",
    "    dict_indices[word] = cont\n",
    "    cont += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bow_tr(tr_txt, V, dict_indices):\n",
    "    tk = TweetTokenizer()\n",
    "    BOW = np.zeros((len(tr_txt),len(V)), dtype=int)\n",
    "    cont_doc = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tk.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in dict_indices:\n",
    "                BOW[cont_doc, dict_indices[word]] = fdist_doc[word]\n",
    "        cont_doc += 1       \n",
    "    return BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dor(TR):\n",
    "    \n",
    "    DTR = np.zeros((TR.shape[1], TR.shape[0]), dtype=np.float)\n",
    "\n",
    "    tam_V = TR.shape[1]\n",
    "    for doc, i in zip(TR, range(len(TR))):\n",
    "        nonzero_positions = np.nonzero(doc)[0] # returns a tuple of n-dimensions. Since we have 1D array docs, it returns a tuple with one element. thus, we get the 0 index.\n",
    "        tam_v = len(nonzero_positions)\n",
    "        for term in nonzero_positions:\n",
    "            DTR[term, i] = (1 + math.log10(doc[term])) * math.log10(tam_V/tam_v)\n",
    "    return DTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dor_docs(TR, tr_txt):\n",
    "    \n",
    "    DDR = np.zeros((len(tr_txt), TR.shape[1]), dtype=np.float)\n",
    "    tk = TweetTokenizer()\n",
    "\n",
    "    for tr, i in zip(tr_txt, range(len(tr_txt))):\n",
    "        doc = np.zeros(TR.shape[1])\n",
    "        for word in tk.tokenize(tr):\n",
    "            if word in dict_indices:\n",
    "                doc = np.add(doc, TR[dict_indices[word],:])\n",
    "        DDR[i] = doc\n",
    "    \n",
    "    return DDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW_tr = build_bow_tr(X_train, V, dict_indices)\n",
    "BOW_val = build_bow_tr(X_val, V, dict_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5544, 5000)\n",
      "(616, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(BOW_tr.shape)\n",
    "print(BOW_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOR_tr = compute_dor(BOW_tr)\n",
    "DOR_val = compute_dor(BOW_val)\n",
    "#DOR_base = preprocessing.normalize(DOR_tr, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 5544)\n",
      "(5000, 616)\n"
     ]
    }
   ],
   "source": [
    "print(DOR_tr.shape)\n",
    "print(DOR_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DOR_train = compute_dor_docs(DOR_tr, X_train)\n",
    "X_DOR_val = compute_dor_docs(DOR_tr, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5544, 5544)\n",
      "(616, 5544)\n"
     ]
    }
   ],
   "source": [
    "print(X_DOR_train.shape)\n",
    "print(X_DOR_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C': [1.5, 2, 2.5, 3, 3.5], 'gamma': [0.005, 0.01, 0.05, 0.1, 0.5]}\n",
    "svr = SVC()\n",
    "grid = GridSearchCV(estimator=svr, param_grid=parameters, n_jobs=8, scoring=\"f1_macro\", cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_DOR_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVC(C=2.5, gamma=0.05)\n",
    "svr.fit(X_DOR_train, y_train)\n",
    "y_pred = svr.predict(X_DOR_val)\n",
    "print(metrics.classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
