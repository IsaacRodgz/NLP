{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 3\n",
    "## Isaac Rodr√≠guez Bribiesca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliotecas usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "from nltk import bigrams\n",
    "from nltk import ngrams\n",
    "import preprocessor as p\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se lee archivo de entrenamiento de tweets, as√≠ como las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mex_train.txt', 'r') as f:\n",
    "    corpus = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mex_train_labels.txt', 'r') as f:\n",
    "    labels = f.readlines()\n",
    "\n",
    "labels = [int(lab.strip('\\n')) for lab in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se separan tweets agresivos y no agresivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_agg = [tw for tw, lab in zip(corpus, labels) if lab == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_noagg = [tw for tw, lab in zip(corpus, labels) if lab == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones para preprocesar los tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_word(w, punct):\n",
    "    is_punct = True if w in punct else False\n",
    "    is_digit = w.isnumeric()\n",
    "    is_stopword = w in stopwords.words('spanish')\n",
    "\n",
    "    return \"\" if is_punct or is_digit or is_stopword else w.lower()\n",
    "\n",
    "def process_sentence(sent, punct):\n",
    "    s = []\n",
    "    for w in sent:\n",
    "\n",
    "        is_punct = True if w in punct else False\n",
    "        is_digit = w.isnumeric()\n",
    "        is_stopword = w in stopwords.words('spanish')\n",
    "\n",
    "        if not(is_punct or is_digit or is_stopword):\n",
    "            s.append(w.lower())\n",
    "\n",
    "    return \" \".join(s)\n",
    "\n",
    "def num_tokens(tweets):\n",
    "    tk = TweetTokenizer()\n",
    "    tokens = [process_word(w, punct) for sent in tweets for w in tk.tokenize(sent)]\n",
    "    tokens = list(filter(None, tokens))\n",
    "    \n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simbolos a filtrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = set(['.', ',', ';', ':', '-', '!', '¬°', '¬ø', '?', '\"', '\\'', '...', '<url>', '*', '@usuario'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funci√≥n para convertir una lista de tokens a ngramas de tama√±o n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_ngrams(words, n, sep=\" \"):\n",
    "    if n > 1:\n",
    "        return [tuple(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "    else:\n",
    "        return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funci√≥n para calcular tabla de frecuencias de ngramas con ayuda de TweetTokenizer y FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngrams(tweets, punct, n):\n",
    "    tk = TweetTokenizer()\n",
    "    tokens = [process_word(w, punct) for sent in tweets for w in tk.tokenize(sent)]\n",
    "    tokens = list(filter(None, tokens))\n",
    "    tw_trigrams = words_to_ngrams(tokens, n)\n",
    "    tw_trigrams = FreqDist(tw_trigrams)\n",
    "    \n",
    "    return tw_trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1. Conteos de unigramas sin suavizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion que genera unigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unigram(tweets, punct):\n",
    "    return build_ngrams(tweets, punct, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1. Conteos de bigramas sin suavizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion que genera bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bigram(tweets, punct):\n",
    "    return build_ngrams(tweets, punct, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2. Comparaci√≥n unigramas y bigramas para clases tweets agresivos y no agresivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigramas y bigramas m√°s comunes en tweets no agresivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigramas tweeets no agresivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_unigrams = build_unigram(tweets_noagg, punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('verga', 864),\n",
       " ('madre', 675),\n",
       " ('putas', 547),\n",
       " ('loca', 542),\n",
       " ('si', 421),\n",
       " ('putos', 359),\n",
       " ('üòÇ', 259),\n",
       " ('bien', 155),\n",
       " ('‚Ä¶', 155),\n",
       " ('vale', 127)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_unigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigramas tweeets no agresivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_bigrams = build_bigram(tweets_noagg, punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('üòÇ', 'üòÇ'), 106),\n",
       " (('vale', 'verga'), 77),\n",
       " (('puta', 'madre'), 70),\n",
       " (('‚ù§', 'Ô∏è'), 38),\n",
       " (('üèª', '\\u200d'), 31),\n",
       " (('valer', 'verga'), 30),\n",
       " (('vale', 'madre'), 30),\n",
       " (('mam√°', 'luchona'), 29),\n",
       " (('üò≠', 'üò≠'), 29),\n",
       " (('üò°', 'üò°'), 25)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_bigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigramas y bigramas m√°s comunes en tweets agresivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigramas tweeets no agresivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_unigrams = build_unigram(tweets_agg, punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('putos',), 472),\n",
       " (('madre',), 404),\n",
       " (('putas',), 348),\n",
       " (('verga',), 284),\n",
       " (('si',), 242),\n",
       " (('hdp',), 215),\n",
       " (('puta',), 171),\n",
       " (('pinche',), 171),\n",
       " (('üòÇ',), 118),\n",
       " (('puto',), 114)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_unigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigramas tweeets no agresivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_bigrams = build_bigram(tweets_agg, punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('puta', 'madre'), 90),\n",
       " (('üòÇ', 'üòÇ'), 59),\n",
       " (('chingar', 'madre'), 32),\n",
       " (('mil', 'putas'), 32),\n",
       " (('chinguen', 'madre'), 32),\n",
       " (('hijo', 'puta'), 28),\n",
       " (('hijos', 'puta'), 27),\n",
       " (('chinga', 'madre'), 27),\n",
       " (('chingas', 'madre'), 27),\n",
       " (('putas', 'madres'), 25)]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_bigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de los unigramas no se observa mucha diferencia en el tipo de palabras m√°s frecuentes entre tweets agresivos y no agresivos, variando s√≥lamente las frecuencias en que aparecen las palabras. En el caso de bigramas se hace m√°s notoria la diferencia entre tweets agresivos y no agresivos, ya que en los tweets agresivos aparecen m√°s groser√≠as como \"hijo puta\" o \"chingas madre\", que en los bigramas de tweeets no agresivos no son tan frecuentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3. Bigramas y Trigramas con Add-one Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen unigramas y bigramas para construir las tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_unigrams = build_unigram(corpus, punct)\n",
    "tw_bigrams = build_bigram(corpus, punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla de bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_table = {}\n",
    "\n",
    "bigram_list = list(tw_bigrams.keys())\n",
    "vocab_size = len(list(tw_unigrams))\n",
    "\n",
    "for v in bigram_list:\n",
    "    if v[0] not in bigram_table:\n",
    "        bigram_table[v[0]] = {}\n",
    "    bigram_table[v[0]][v[1]] = (tw_bigrams[(v[0], v[1])] + 1)/(tw_unigrams[v[0]] + vocab_size)\n",
    "\n",
    "for v in bigram_list:\n",
    "    if v[1] not in bigram_table:\n",
    "        bigram_table[v[1]] = {}\n",
    "    bigram_table[v[1]][v[0]] = 1/(tw_unigrams[v[1]] + vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_table = {}\n",
    "\n",
    "bigram_list = list(tw_bigrams.keys())\n",
    "vocab_size = len(list(tw_unigrams))\n",
    "\n",
    "unigram_vocab = list(tw_unigrams.keys())\n",
    "    \n",
    "for v1 in unigram_vocab:\n",
    "    for v2 in unigram_vocab:\n",
    "        \n",
    "        if (v1, v2) in tw_bigrams:\n",
    "            if v1 not in bigram_table:\n",
    "                bigram_table[v1] = {}\n",
    "            bigram_table[v1][v2] = (tw_bigrams[(v1, v2)] + 1)/(tw_unigrams[v1] + vocab_size)\n",
    "            \n",
    "        else:\n",
    "            if v1 not in bigram_table:\n",
    "                bigram_table[v1] = {}\n",
    "            bigram_table[v1][v2] = 1/(tw_unigrams[v1] + vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obteniendo trigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_trigrams = build_ngrams(corpus, punct, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla de trigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_table = {}\n",
    "\n",
    "trigram_list = list(tw_trigrams.keys())\n",
    "vocab_size = len(list(tw_bigrams))\n",
    "\n",
    "for v in trigram_list:\n",
    "    if v[0] not in trigram_table:\n",
    "        trigram_table[v[0]] = {}\n",
    "\n",
    "    if v[1] not in trigram_table[v[0]]:\n",
    "        trigram_table[v[0]][v[1]] = {}\n",
    "    \n",
    "    trigram_table[v[0]][v[1]][v[2]] = (tw_trigrams[(v[0], v[1], v[2])] + 1)/(tw_bigrams[(v[0], v[1])] + vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4. Bigramas y Trigramas con Good-Turing Disccount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los valores de $N_{c+1}$ que no existan, se ajustar√° un modelo de ley de potencia: $N_{c+1} = a*(c+1)^{b}$ con $b < -1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_law(coeffs, x):\n",
    "    return np.exp(coeffs[1])*(x**(coeffs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla de bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_table = {}\n",
    "\n",
    "bigram_list = list(tw_bigrams.keys())\n",
    "N = len(bigram_list)\n",
    "\n",
    "# Calcula conteo N_c\n",
    "limit = 20  # A paritr de este valor se usa el modelo de ley de potencia\n",
    "Nk = {}\n",
    "for f in set(tw_bigrams.values()):\n",
    "    if f >= 20:\n",
    "        break\n",
    "    Nk[f] = len([w for w in tw_bigrams.keys() if tw_bigrams[w] == f])\n",
    "\n",
    "# Ajusta modelo de ley de potencia\n",
    "Nk_log = []\n",
    "k = []\n",
    "for f in set(tw_bigrams.values()):\n",
    "    Nk_log.append(np.log(len([w for w in tw_bigrams.keys() if tw_bigrams[w] == f])))\n",
    "    k.append(np.log(f))\n",
    "    \n",
    "Nk_log = np.array(Nk_log)\n",
    "k = np.array(k)\n",
    "z = np.polyfit(k, Nk_log, 1)\n",
    "\n",
    "# Calcula tabla de bigramas\n",
    "for v in bigram_list:\n",
    "    \n",
    "    if v[0] not in bigram_table:\n",
    "        bigram_table[v[0]] = {}\n",
    "        \n",
    "    if tw_bigrams[(v[0], v[1])] > limit or (tw_bigrams[(v[0], v[1])]+1) not in Nk:\n",
    "        c = power_law(z, tw_bigrams[(v[0], v[1])]+1)\n",
    "    else:\n",
    "        c = (tw_bigrams[(v[0], v[1])] + 1)*(Nk[tw_bigrams[(v[0], v[1])]+1]/Nk[tw_bigrams[(v[0], v[1])]])\n",
    "\n",
    "    bigram_table[v[0]][v[1]] = c/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla de trigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_table = {}\n",
    "\n",
    "trigram_list = list(tw_trigrams.keys())\n",
    "N = len(trigram_list)\n",
    "\n",
    "# Calcula conteo N_c\n",
    "limit = 20  # A paritr de este valor se usa el modelo de ley de potencia\n",
    "Nk = {}\n",
    "for f in set(tw_trigrams.values()):\n",
    "    if f >= 20:\n",
    "        break\n",
    "    Nk[f] = len([w for w in tw_trigrams.keys() if tw_trigrams[w] == f])\n",
    "\n",
    "# Ajusta modelo de ley de potencia\n",
    "Nk_log = []\n",
    "k = []\n",
    "for f in set(tw_trigrams.values()):\n",
    "    Nk_log.append(np.log(len([w for w in tw_trigrams.keys() if tw_trigrams[w] == f])))\n",
    "    k.append(np.log(f))\n",
    "    \n",
    "Nk_log = np.array(Nk_log)\n",
    "k = np.array(k)\n",
    "z = np.polyfit(k, Nk_log, 1)\n",
    "\n",
    "# Calcula tabla de bigramas\n",
    "for v in trigram_list:\n",
    "    if v[0] not in trigram_table:\n",
    "        trigram_table[v[0]] = {}\n",
    "\n",
    "    if v[1] not in trigram_table[v[0]]:\n",
    "        trigram_table[v[0]][v[1]] = {}\n",
    "        \n",
    "    if tw_trigrams[(v[0], v[1], v[2])] > limit or (tw_trigrams[(v[0], v[1], v[2])]+1) not in Nk:\n",
    "        c = power_law(z, tw_trigrams[(v[0], v[1], v[2])]+1)\n",
    "    else:\n",
    "        c = (tw_trigrams[(v[0], v[1], v[2])] + 1)*(Nk[tw_trigrams[(v[0], v[1], v[2])]+1]/Nk[tw_trigrams[(v[0], v[1], v[2])]])\n",
    "\n",
    "    bigram_table[v[0]][v[1], v[2]] = c/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5. Modelo lenguaje con Add-one Smoothing en tweets agresivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ngram():\n",
    "    \n",
    "    def __init__(self, corpus, punct):\n",
    "        self.corpus = corpus\n",
    "        self.punct = punct\n",
    "        \n",
    "        self.unigrams = self.build_ngrams(1)\n",
    "        self.bigrams = self.build_ngrams(2)\n",
    "        self.trigrams = self.build_ngrams(3)\n",
    "        \n",
    "        self.unigram_vocab = set(self.unigrams.keys())\n",
    "        self.bigram_vocab = set(self.bigrams.keys())\n",
    "        self.trigram_vocab = set(self.trigrams.keys())\n",
    "        self.unigram_size = len(self.unigram_vocab)\n",
    "        self.bigram_size = len(self.bigram_vocab)\n",
    "        self.trigram_size = len(self.trigram_vocab)\n",
    "\n",
    "        self.bigrams_table = self.build_bigram_table()\n",
    "        self.trigrams_table = self.build_trigram_table()\n",
    "        \n",
    "    def process_word(self, w):\n",
    "        is_punct = True if w in self.punct else False\n",
    "        is_digit = w.isnumeric()\n",
    "        is_stopword = w in stopwords.words('spanish')\n",
    "\n",
    "        return \"\" if is_punct or is_digit else w.lower()\n",
    "        \n",
    "    def build_ngrams(self, n):\n",
    "        tk = TweetTokenizer()\n",
    "        tokens = [self.process_word(w) for sent in self.corpus for w in tk.tokenize(sent)]\n",
    "        tokens = list(filter(None, tokens))\n",
    "        tw_ngrams = words_to_ngrams(tokens, n)\n",
    "        tw_ngrams = FreqDist(tw_ngrams)\n",
    "\n",
    "        return tw_ngrams\n",
    "    \n",
    "    def build_bigram_table(self):\n",
    "        bigram_table = {}\n",
    "\n",
    "        for v in self.bigram_vocab:\n",
    "            if v[0] not in bigram_table:\n",
    "                bigram_table[v[0]] = {}\n",
    "            bigram_table[v[0]][v[1]] = (self.bigrams[(v[0], v[1])] + 1)/(self.unigrams[v[0]] + self.bigram_size)\n",
    "        \n",
    "        return bigram_table\n",
    "    \n",
    "    def build_trigram_table(self):\n",
    "        trigram_table = {}\n",
    "\n",
    "        for v in self.trigram_vocab:\n",
    "            if v[0] not in trigram_table:\n",
    "                trigram_table[v[0]] = {}\n",
    "\n",
    "            if v[1] not in trigram_table[v[0]]:\n",
    "                trigram_table[v[0]][v[1]] = {}\n",
    "\n",
    "            trigram_table[v[0]][v[1]][v[2]] = (self.trigrams[(v[0], v[1], v[2])] + 1)/(self.bigrams[(v[0], v[1])] + self.trigram_size)\n",
    "        return trigram_table\n",
    "    \n",
    "    def prob_sentence_bigram(self, s):\n",
    "        words_split = s.split()\n",
    "        words = []\n",
    "        for w in words_split:\n",
    "            if w in self.unigram_vocab:\n",
    "                words.append(w)\n",
    "                \n",
    "        if len(words) == 0:\n",
    "            return 0\n",
    "        \n",
    "        prob = 0\n",
    "        prob += np.log(self.unigrams[words[0]]/self.unigram_size)\n",
    "        \n",
    "        if len(words) == 1:\n",
    "            return -prob\n",
    "        elif len(words) == 2:\n",
    "            prob += np.log(self.prob_bigram(words[1], words[0]))\n",
    "            return -prob\n",
    "        \n",
    "        for i in range(1, len(words)-1):\n",
    "            prob += np.log(self.prob_bigram(words[i+1], words[i]))\n",
    "        \n",
    "        return -prob\n",
    "    \n",
    "    def prob_bigram(self, w2, w1):\n",
    "        if w1 in self.bigrams_table and w2 in self.bigrams_table[w1]:\n",
    "            return self.bigrams_table[w1][w2]\n",
    "        else:\n",
    "            return 1/(self.unigrams[w1] + self.bigram_size)\n",
    "        \n",
    "    def prob_sentence_trigram(self, s):\n",
    "        words_split = s.split()\n",
    "        words = []\n",
    "        for w in words_split:\n",
    "            if w in self.unigram_vocab:\n",
    "                words.append(w)\n",
    "                \n",
    "        if len(words) == 0:\n",
    "            return 0\n",
    "        \n",
    "        prob = 0\n",
    "        prob += self.unigrams[words[0]]/self.unigram_size\n",
    "        \n",
    "        if len(words) == 1:\n",
    "            return -prob\n",
    "        elif len(words) == 2:\n",
    "            prob += np.log(self.prob_bigram(words[1], words[0]))\n",
    "            return -prob\n",
    "        elif len(words) == 3:\n",
    "            prob += np.log(self.prob_trigram(words[2], words[0], words[1]))\n",
    "            return -prob\n",
    "        \n",
    "        for i in range(1, len(words)-2):\n",
    "            prob += np.log(self.prob_trigram(words[i+2], words[i], words[i+1]))\n",
    "        \n",
    "        return -prob\n",
    "    \n",
    "    def prob_trigram(self, w3, w1, w2):\n",
    "        if w1 in self.trigrams_table and w2 in self.trigrams_table[w1] and w3 in self.trigrams_table[w1][w2]:\n",
    "            return self.trigrams_table[w1][w2][w3]\n",
    "        else:\n",
    "            return 1/(self.bigrams[(w1, w2)] + self.trigram_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ngram(tweets_agg, punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2884328463463779e-05"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prob_sentence_bigram(\"hijo de puta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.962210844651776e-06"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prob_sentence_bigram(\"de puta hijo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.241810949130512e-06"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prob_sentence_trigram(\"hijo de puta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.643867211531108e-06"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prob_sentence_trigram(\"de puta hijo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios 6 y 7. Perplejidad para modelo de bigramas y trigramas en tweets agresivos de conjunto de datos test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se leen los datos del conjunto test de la clase 1 (agresivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mex_test.txt', 'r') as f:\n",
    "    corpus_test = f.readlines()\n",
    "    \n",
    "with open('mex_test_labels.txt', 'r') as f:\n",
    "    labels_test = f.readlines()\n",
    "\n",
    "labels_test = [int(lab.strip('\\n')) for lab in labels_test]\n",
    "tweets_agg_test = [tw for tw, lab in zip(corpus_test, labels_test) if lab == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_test = \" \".join([s.strip('\\n') for s in tweets_agg_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean los modelos de bigramas y trigramas con el conjunto de training de la clase 1 (agresivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mex_train.txt', 'r') as f:\n",
    "    corpus_train = f.readlines()\n",
    "    \n",
    "with open('mex_train_labels.txt', 'r') as f:\n",
    "    labels_train = f.readlines()\n",
    "\n",
    "labels_train = [int(lab.strip('\\n')) for lab in labels_train]\n",
    "tweets_agg_train = [tw for tw, lab in zip(corpus_train, labels_train) if lab == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ngram(tweets_agg_train, punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = num_tokens(tweets_agg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se calcula perplejidad del modelo de bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.002027839277331"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(1./model.prob_sentence_bigram(sentence_test), -1./N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se calcula perplejidad del modelo de trigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0020350653129673"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(1./model.prob_sentence_trigram(sentence_test), -1./N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 8. Modelo combinado (unigramas, bigramas y trigramas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrigramInterpolation():\n",
    "    \n",
    "    def __init__(self, corpus, punct):\n",
    "        self.corpus = corpus\n",
    "        self.punct = punct\n",
    "        \n",
    "        self.unigrams = self.build_ngrams(1)\n",
    "        self.bigrams = self.build_ngrams(2)\n",
    "        self.trigrams = self.build_ngrams(3)\n",
    "        \n",
    "        self.unigram_vocab = set(self.unigrams.keys())\n",
    "        self.bigram_vocab = set(self.bigrams.keys())\n",
    "        self.trigram_vocab = set(self.trigrams.keys())\n",
    "        self.unigram_size = len(self.unigram_vocab)\n",
    "        self.bigram_size = len(self.bigram_vocab)\n",
    "        self.trigram_size = len(self.trigram_vocab)\n",
    "\n",
    "        self.bigrams_table = self.build_bigram_table()\n",
    "        self.trigrams_table = self.build_trigram_table()\n",
    "        \n",
    "        self.lambda1 = 0.6\n",
    "        self.lambda2 = 0.3\n",
    "        self.lambda3 = 0.1\n",
    "        \n",
    "    def process_word(self, w):\n",
    "        is_punct = True if w in self.punct else False\n",
    "        is_digit = w.isnumeric()\n",
    "        is_stopword = w in stopwords.words('spanish')\n",
    "\n",
    "        return \"\" if is_punct or is_digit or is_stopword else w.lower()\n",
    "        \n",
    "    def build_ngrams(self, n):\n",
    "        tk = TweetTokenizer()\n",
    "        tokens = [self.process_word(w) for sent in self.corpus for w in tk.tokenize(sent)]\n",
    "        tokens = list(filter(None, tokens))\n",
    "        tw_ngrams = words_to_ngrams(tokens, n)\n",
    "        tw_ngrams = FreqDist(tw_ngrams)\n",
    "\n",
    "        return tw_ngrams\n",
    "    \n",
    "    def build_bigram_table(self):\n",
    "        bigram_table = {}\n",
    "\n",
    "        for v in self.bigram_vocab:\n",
    "            if v[0] not in bigram_table:\n",
    "                bigram_table[v[0]] = {}\n",
    "            bigram_table[v[0]][v[1]] = (self.bigrams[(v[0], v[1])] + 1)/(self.unigrams[v[0]] + self.bigram_size)\n",
    "        \n",
    "        return bigram_table\n",
    "    \n",
    "    def build_trigram_table(self):\n",
    "        trigram_table = {}\n",
    "\n",
    "        for v in self.trigram_vocab:\n",
    "            if v[0] not in trigram_table:\n",
    "                trigram_table[v[0]] = {}\n",
    "\n",
    "            if v[1] not in trigram_table[v[0]]:\n",
    "                trigram_table[v[0]][v[1]] = {}\n",
    "\n",
    "            trigram_table[v[0]][v[1]][v[2]] = (self.trigrams[(v[0], v[1], v[2])] + 1)/(self.bigrams[(v[0], v[1])] + self.trigram_size)\n",
    "        return trigram_table\n",
    "    \n",
    "    def prob_sentence_bigram(self, s):\n",
    "        words_split = s.split()\n",
    "        words = []\n",
    "        for w in words_split:\n",
    "            if w in self.unigram_vocab:\n",
    "                words.append(w)\n",
    "                \n",
    "        if len(words) == 0:\n",
    "            return 0\n",
    "        \n",
    "        prob = 0\n",
    "        prob += np.log(self.unigrams[words[0]]/self.unigram_size)\n",
    "        \n",
    "        if len(words) == 1:\n",
    "            return -prob\n",
    "        elif len(words) == 2:\n",
    "            prob += np.log(self.prob_bigram(words[1], words[0]))\n",
    "            return -prob\n",
    "        \n",
    "        for i in range(1, len(words)-1):\n",
    "            prob += np.log(self.prob_bigram(words[i+1], words[i]))\n",
    "        \n",
    "        return -prob\n",
    "    \n",
    "    def prob_bigram(self, w2, w1):\n",
    "        if w1 in self.bigrams_table and w2 in self.bigrams_table[w1]:\n",
    "            return self.bigrams_table[w1][w2]\n",
    "        else:\n",
    "            return 1./(self.unigrams[w1] + self.bigram_size)\n",
    "        \n",
    "    def prob_sentence_trigram(self, s):\n",
    "        words_split = s.split()\n",
    "        words = []\n",
    "        for w in words_split:\n",
    "            if w in self.unigram_vocab:\n",
    "                words.append(w)\n",
    "                \n",
    "        if len(words) == 0:\n",
    "            return 0\n",
    "        \n",
    "        prob = 0\n",
    "        prob += np.log(self.unigrams[words[0]]/self.unigram_size)\n",
    "        \n",
    "        if len(words) == 1:\n",
    "            return -prob\n",
    "        elif len(words) == 2:\n",
    "            prob += np.log(self.prob_bigram(words[1], words[0]))\n",
    "            return -prob\n",
    "        elif len(words) == 3:\n",
    "            prob += np.log(self.prob_trigram(words[2], words[0], words[1]))\n",
    "            return -prob\n",
    "        \n",
    "        for i in range(1, len(words)-2):\n",
    "            prob += np.log(self.prob_trigram(words[i+2], words[i], words[i+1]))\n",
    "        \n",
    "        return -prob\n",
    "    \n",
    "    def prob_trigram(self, w3, w1, w2):\n",
    "        if w1 in self.trigrams_table and w2 in self.trigrams_table[w1] and w3 in self.trigrams_table[w1][w2]:\n",
    "            return self.trigrams_table[w1][w2][w3]\n",
    "        else:\n",
    "            return 1./(self.bigrams[(w1, w2)] + self.trigram_size)\n",
    "        \n",
    "    def prob_sentence_trigram_interpol(self, s):\n",
    "        words_split = s.split()\n",
    "        words = []\n",
    "        for w in words_split:\n",
    "            if w in self.unigram_vocab:\n",
    "                words.append(w)\n",
    "                \n",
    "        if len(words) == 0:\n",
    "            return 0\n",
    "        \n",
    "        prob = 0\n",
    "        prob += np.log(self.unigrams[words[0]]/self.unigram_size)\n",
    "        \n",
    "        if len(words) == 1:\n",
    "            return -prob\n",
    "        elif len(words) == 2:\n",
    "            prob += np.log(self.prob_bigram(words[1], words[0]))\n",
    "            return -prob\n",
    "        elif len(words) == 3:\n",
    "            prob += np.log(self.prob_trigram_interpol(words[2], words[0], words[1]))\n",
    "            return -prob\n",
    "        \n",
    "        for i in range(1, len(words)-2):\n",
    "            prob += np.log(self.prob_trigram_interpol(words[i+2], words[i], words[i+1]))\n",
    "        \n",
    "        return -prob\n",
    "    \n",
    "    def prob_trigram_interpol(self, w3, w1, w2):\n",
    "        prob = 0\n",
    "        if w1 in self.trigrams_table and w2 in self.trigrams_table[w1] and w3 in self.trigrams_table[w1][w2]:\n",
    "            prob += self.lambda1*self.trigrams_table[w1][w2][w3]\n",
    "        else:\n",
    "            prob += self.lambda1*(1./(self.bigrams[(w1, w2)] + self.trigram_size))\n",
    "            \n",
    "        if w2 in self.bigrams_table and w3 in self.bigrams_table[w2]:\n",
    "            prob += self.lambda2*self.bigrams_table[w2][w3]\n",
    "        else:\n",
    "            prob += self.lambda2*(1./(self.unigrams[w2] + self.bigram_size))\n",
    "            \n",
    "        if w3 in self.unigrams:\n",
    "            prob += self.lambda3*self.unigrams[w3]\n",
    "        else:\n",
    "            prob += self.lambda3*(1./self.unigram_size)\n",
    "            \n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea modelo combinado mediante interpolaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrigramInterpolation(tweets_agg_train, punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercico 9. Perplejidad modelo combinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985662601545036"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(-model.prob_sentence_trigram_interpol(sentence_test), -1./N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 10. Funci√≥n agredir() para generar oraciones a partir de modelo de trigramas add-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agredir(model):\n",
    "    \n",
    "    vocab = list(model.unigrams.keys())\n",
    "    \n",
    "    # Get random firts word\n",
    "    index = np.random.randint(0,len(vocab),1)[0]\n",
    "    first_word = vocab[index]\n",
    "    \n",
    "    # Get second word according to bigram probabilities\n",
    "    max_prob = max(model.bigrams_table[first_word].values())\n",
    "    max_prob_words = [k for k, v in model.bigrams_table[first_word].items() if v == max_prob]\n",
    "    \n",
    "    if len(max_prob_words) == 1:\n",
    "        next_word = max_prob_words[0]\n",
    "    else:\n",
    "        index = np.random.randint(0,len(max_prob_words),1)[0]\n",
    "        next_word = max_prob_words[index]\n",
    "        \n",
    "    sentence = [first_word, next_word]\n",
    "    max_len = 30\n",
    "    curr_len = 2\n",
    "    \n",
    "    # Get the next words according to trigram probabilities, until '</s>' is obtained or max length is reached\n",
    "    while next_word != \"</s>\" and curr_len < max_len:\n",
    "        \n",
    "        max_prob = max(model.trigrams_table[sentence[-2]][sentence[-1]].values())\n",
    "        max_prob_words = [k for k, v in model.trigrams_table[sentence[-2]][sentence[-1]].items() if v == max_prob]\n",
    "\n",
    "        if len(max_prob_words) == 1:\n",
    "            next_word = max_prob_words[0]\n",
    "        else:\n",
    "            index = np.random.randint(0,len(max_prob_words),1)[0]\n",
    "            next_word = max_prob_words[index]\n",
    "            \n",
    "        sentence.append(next_word)\n",
    "        curr_len += 1\n",
    "\n",
    "    return \" \".join(sentence[:-1]).strip(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se a√±ade s√≠mbolo '</s>' al final de cada tweet para incluirlo en las probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mex_train.txt', 'r') as f:\n",
    "    corpus_train = f.readlines()\n",
    "    \n",
    "with open('mex_train_labels.txt', 'r') as f:\n",
    "    labels_train = f.readlines()\n",
    "\n",
    "labels_train = [int(lab.strip('\\n')) for lab in labels_train]\n",
    "tweets_agg_train = [tw.strip('\\n')+' </s>' for tw, lab in zip(corpus_train, labels_train) if lab == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea modelo de trigramas con dataset de entrenamiento en tweets agresivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ngram(tweets_agg_train, punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplos de tweets generados a partir de trigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1: jaja \n",
      "\n",
      "Tweet 2: #amlo no confronte a los putos de los putos gringos de mierda \n",
      "\n",
      "Tweet 3: golf los encinos s a \n",
      "\n",
      "Tweet 4: csm el mal parido que gusto saber de ti y eso le ense√±as a tus putos amigos mamones piensen üôÇ \n",
      "\n",
      "Tweet 5: fama y la gente que se vaya a chingar a su madre \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Tweet {0}: {1} \\n\".format(i+1, agredir(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 11. Modelo de clasificaci√≥n a partir de bigramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se leen tweets de conjunto training no agresivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mex_train.txt', 'r') as f:\n",
    "    corpus_train = f.readlines()\n",
    "    \n",
    "with open('mex_train_labels.txt', 'r') as f:\n",
    "    labels_train = f.readlines()\n",
    "\n",
    "labels_train = [int(lab.strip('\\n')) for lab in labels_train]\n",
    "tweets_noagg_train = [tw.strip('\\n') for tw, lab in zip(corpus_train, labels_train) if lab == 0]\n",
    "tweets_agg_train = [tw.strip('\\n') for tw, lab in zip(corpus_train, labels_train) if lab == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean los dos modelos de bigramas, para tweets agresivos y no agresivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_noagg = Ngram(tweets_noagg_train, punct)\n",
    "model_agg = Ngram(tweets_agg_train, punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cargan datos de test para evaluar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mex_test.txt', 'r') as f:\n",
    "    corpus_test = f.readlines()\n",
    "    \n",
    "with open('mex_test_labels.txt', 'r') as f:\n",
    "    labels_test = f.readlines()\n",
    "\n",
    "labels_test = [int(lab.strip('\\n')) for lab in labels_test]\n",
    "tweets_test = [tw.strip('\\n') for tw in corpus_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realiza predicciones en datos de conjunto test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "for tweet in tweets_test:\n",
    "    if model_noagg.prob_sentence_bigram(tweet) > model_agg.prob_sentence_bigram(tweet):\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        y_pred.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 12. Evaluaci√≥n de modelo con m√©tricas: Accuracy y F-score en clase positiva, negativa y Macro F-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = np.array(labels_test)\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5688311688311688\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(labels_test == y_pred)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-score para clase tweets agresivos (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score clase 1:  0.2766884531590414\n"
     ]
    }
   ],
   "source": [
    "TP = y_pred[labels_test == y_pred]\n",
    "\n",
    "precision_1 = np.sum(TP==1)/np.sum(y_pred==1)\n",
    "recall_1 =  np.sum(TP==1)/np.sum(labels_test==1)\n",
    "\n",
    "f1_score_1 = 2*((precision_1*recall_1)/(precision_1+recall_1))\n",
    "\n",
    "print(\"F1-Score clase 1: \", f1_score_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-score para clase tweets no agresivos (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score clase 0:  0.6928769657724329\n"
     ]
    }
   ],
   "source": [
    "TP = y_pred[labels_test == y_pred]\n",
    "\n",
    "precision_0 = np.sum(TP==0)/np.sum(y_pred==0)\n",
    "recall_0 =  np.sum(TP==0)/np.sum(labels_test==0)\n",
    "\n",
    "f1_score_0 = 2*((precision_0*recall_0)/(precision_0+recall_0))\n",
    "\n",
    "print(\"F1-Score clase 0: \", f1_score_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-score macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score macro:  0.4847827094657371\n"
     ]
    }
   ],
   "source": [
    "f1_score_macro = (f1_score_0 + f1_score_1)/2\n",
    "\n",
    "print(\"F1-Score macro: \", f1_score_macro)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
