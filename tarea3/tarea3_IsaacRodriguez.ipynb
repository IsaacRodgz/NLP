{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 3\n",
    "## Isaac Rodr√≠guez Bribiesca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliotecas usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "from nltk import bigrams\n",
    "from nltk import ngrams\n",
    "import preprocessor as p\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se lee archivo de entrenamiento de tweets, as√≠ como las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mex_train.txt', 'r') as f:\n",
    "    corpus = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mex_train_labels.txt', 'r') as f:\n",
    "    labels = f.readlines()\n",
    "\n",
    "labels = [int(lab.strip('\\n')) for lab in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se separan tweets agresivos y no agresivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_agg = [tw for tw, lab in zip(corpus, labels) if lab == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_noagg = [tw for tw, lab in zip(corpus, labels) if lab == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones para preprocesar los tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_word(w, punct):\n",
    "    is_punct = True if w in punct else False\n",
    "    is_digit = w.isnumeric()\n",
    "    is_stopword = w in stopwords.words('spanish')\n",
    "\n",
    "    return \"\" if is_punct or is_digit or is_stopword else w.lower()\n",
    "\n",
    "def process_sentence(sent, punct):\n",
    "    s = []\n",
    "    for w in sent:\n",
    "\n",
    "        is_punct = True if w in punct else False\n",
    "        is_digit = w.isnumeric()\n",
    "        is_stopword = w in stopwords.words('spanish')\n",
    "\n",
    "        if not(is_punct or is_digit or is_stopword):\n",
    "            s.append(w.lower())\n",
    "\n",
    "    return \" \".join(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simbolos a filtrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = set(['.', ',', ';', ':', '-', '!', '¬°', '¬ø', '?', '\"', '\\'', '...', '<url>', '*', '@usuario'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funci√≥n para convertir una lista de tokens a ngramas de tama√±o n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_ngrams(words, n, sep=\" \"):\n",
    "    if n > 1:\n",
    "        return [tuple(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "    else:\n",
    "        return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funci√≥n para calcular tabla de frecuencias de ngramas con ayuda de TweetTokenizer y FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngrams(tweets, punct, n):\n",
    "    tk = TweetTokenizer()\n",
    "    tokens = [process_word(w, punct) for sent in tweets for w in tk.tokenize(sent)]\n",
    "    tokens = list(filter(None, tokens))\n",
    "    tw_trigrams = words_to_ngrams(tokens, n)\n",
    "    tw_trigrams = FreqDist(tw_trigrams)\n",
    "    \n",
    "    return tw_trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1. Conteos de unigramas sin suavizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion que genera unigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unigram(tweets, punct):\n",
    "    return build_ngrams(tweets, punct, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1. Conteos de bigramas sin suavizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion que genera bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bigram(tweets, punct):\n",
    "    return build_ngrams(tweets, punct, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2. Comparaci√≥n unigramas y bigramas para clases tweets agresivos y no agresivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigramas y bigramas m√°s comunes en tweets no agresivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigramas tweeets no agresivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_unigrams = build_unigram(tweets_noagg, punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('verga', 864),\n",
       " ('madre', 675),\n",
       " ('putas', 547),\n",
       " ('loca', 542),\n",
       " ('si', 421),\n",
       " ('putos', 359),\n",
       " ('üòÇ', 259),\n",
       " ('bien', 155),\n",
       " ('‚Ä¶', 155),\n",
       " ('vale', 127)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_unigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigramas tweeets no agresivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_bigrams = build_bigram(tweets_noagg, punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('üòÇ', 'üòÇ'), 106),\n",
       " (('vale', 'verga'), 77),\n",
       " (('puta', 'madre'), 70),\n",
       " (('‚ù§', 'Ô∏è'), 38),\n",
       " (('üèª', '\\u200d'), 31),\n",
       " (('valer', 'verga'), 30),\n",
       " (('vale', 'madre'), 30),\n",
       " (('mam√°', 'luchona'), 29),\n",
       " (('üò≠', 'üò≠'), 29),\n",
       " (('üò°', 'üò°'), 25)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_bigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigramas y bigramas m√°s comunes en tweets agresivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigramas tweeets no agresivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_unigrams = build_unigram(tweets_agg, punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('putos',), 472),\n",
       " (('madre',), 404),\n",
       " (('putas',), 348),\n",
       " (('verga',), 284),\n",
       " (('si',), 242),\n",
       " (('hdp',), 215),\n",
       " (('puta',), 171),\n",
       " (('pinche',), 171),\n",
       " (('üòÇ',), 118),\n",
       " (('puto',), 114)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_unigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigramas tweeets no agresivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_bigrams = build_bigram(tweets_agg, punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('puta', 'madre'), 90),\n",
       " (('üòÇ', 'üòÇ'), 59),\n",
       " (('chingar', 'madre'), 32),\n",
       " (('mil', 'putas'), 32),\n",
       " (('chinguen', 'madre'), 32),\n",
       " (('hijo', 'puta'), 28),\n",
       " (('hijos', 'puta'), 27),\n",
       " (('chinga', 'madre'), 27),\n",
       " (('chingas', 'madre'), 27),\n",
       " (('putas', 'madres'), 25)]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_bigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de los unigramas no se observa mucha diferencia en el tipo de palabras m√°s frecuentes entre tweets agresivos y no agresivos, variando s√≥lamente las frecuencias en que aparecen las palabras. En el caso de bigramas se hace m√°s notoria la diferencia entre tweets agresivos y no agresivos, ya que en los tweets agresivos aparecen m√°s groser√≠as como \"hijo puta\" o \"chingas madre\", que en los bigramas de tweeets no agresivos no son tan frecuentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3. Bigramas y Trigramas con Add-one Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen unigramas y bigramas para construir las tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_unigrams = build_unigram(corpus, punct)\n",
    "tw_bigrams = build_bigram(corpus, punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla de bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_table = {}\n",
    "\n",
    "bigram_list = list(tw_bigrams.keys())\n",
    "vocab_size = len(list(tw_unigrams))\n",
    "\n",
    "for v in bigram_list:\n",
    "    if v[0] not in bigram_table:\n",
    "        bigram_table[v[0]] = {}\n",
    "    bigram_table[v[0]][v[1]] = (tw_bigrams[(v[0], v[1])] + 1)/(tw_unigrams[v[0]] + vocab_size)\n",
    "\n",
    "for v in bigram_list:\n",
    "    if v[1] not in bigram_table:\n",
    "        bigram_table[v[1]] = {}\n",
    "    bigram_table[v[1]][v[0]] = 1/(tw_unigrams[v[1]] + vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_table = {}\n",
    "\n",
    "bigram_list = list(tw_bigrams.keys())\n",
    "vocab_size = len(list(tw_unigrams))\n",
    "\n",
    "unigram_vocab = list(tw_unigrams.keys())\n",
    "    \n",
    "for v1 in unigram_vocab:\n",
    "    for v2 in unigram_vocab:\n",
    "        \n",
    "        if (v1, v2) in tw_bigrams:\n",
    "            if v1 not in bigram_table:\n",
    "                bigram_table[v1] = {}\n",
    "            bigram_table[v1][v2] = (tw_bigrams[(v1, v2)] + 1)/(tw_unigrams[v1] + vocab_size)\n",
    "            \n",
    "        else:\n",
    "            if v1 not in bigram_table:\n",
    "                bigram_table[v1] = {}\n",
    "            bigram_table[v1][v2] = 1/(tw_unigrams[v1] + vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obteniendo trigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_trigrams = build_ngrams(corpus, punct, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla de trigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_table = {}\n",
    "\n",
    "trigram_list = list(tw_trigrams.keys())\n",
    "vocab_size = len(list(tw_bigrams))\n",
    "\n",
    "for v in trigram_list:\n",
    "    if v[0] not in trigram_table:\n",
    "        trigram_table[v[0]] = {}\n",
    "\n",
    "    if v[1] not in trigram_table[v[0]]:\n",
    "        trigram_table[v[0]][v[1]] = {}\n",
    "    \n",
    "    trigram_table[v[0]][v[1]][v[2]] = (tw_trigrams[(v[0], v[1], v[2])] + 1)/(tw_bigrams[(v[0], v[1])] + vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4. Bigramas y Trigramas con Good-Turing Disccount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los valores de $N_{c+1}$ que no existan, se ajustar√° un modelo de ley de potencia: $N_{c+1} = a*(c+1)^{b}$ con $b < -1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_law(coeffs, x):\n",
    "    return np.exp(coeffs[1])*(x**(coeffs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla de bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_table = {}\n",
    "\n",
    "bigram_list = list(tw_bigrams.keys())\n",
    "N = len(bigram_list)\n",
    "\n",
    "# Calcula conteo N_c\n",
    "limit = 20  # A paritr de este valor se usa el modelo de ley de potencia\n",
    "Nk = {}\n",
    "for f in set(tw_bigrams.values()):\n",
    "    if f >= 20:\n",
    "        break\n",
    "    Nk[f] = len([w for w in tw_bigrams.keys() if tw_bigrams[w] == f])\n",
    "\n",
    "# Ajusta modelo de ley de potencia\n",
    "Nk_log = []\n",
    "k = []\n",
    "for f in set(tw_bigrams.values()):\n",
    "    Nk_log.append(np.log(len([w for w in tw_bigrams.keys() if tw_bigrams[w] == f])))\n",
    "    k.append(np.log(f))\n",
    "    \n",
    "Nk_log = np.array(Nk_log)\n",
    "k = np.array(k)\n",
    "z = np.polyfit(k, Nk_log, 1)\n",
    "\n",
    "# Calcula tabla de bigramas\n",
    "for v in bigram_list:\n",
    "    \n",
    "    if v[0] not in bigram_table:\n",
    "        bigram_table[v[0]] = {}\n",
    "        \n",
    "    if tw_bigrams[(v[0], v[1])] > limit or (tw_bigrams[(v[0], v[1])]+1) not in Nk:\n",
    "        c = power_law(z, tw_bigrams[(v[0], v[1])]+1)\n",
    "    else:\n",
    "        c = (tw_bigrams[(v[0], v[1])] + 1)*(Nk[tw_bigrams[(v[0], v[1])]+1]/Nk[tw_bigrams[(v[0], v[1])]])\n",
    "\n",
    "    bigram_table[v[0]][v[1]] = c/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla de trigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_table = {}\n",
    "\n",
    "trigram_list = list(tw_trigrams.keys())\n",
    "N = len(trigram_list)\n",
    "\n",
    "# Calcula conteo N_c\n",
    "limit = 20  # A paritr de este valor se usa el modelo de ley de potencia\n",
    "Nk = {}\n",
    "for f in set(tw_trigrams.values()):\n",
    "    if f >= 20:\n",
    "        break\n",
    "    Nk[f] = len([w for w in tw_trigrams.keys() if tw_trigrams[w] == f])\n",
    "\n",
    "# Ajusta modelo de ley de potencia\n",
    "Nk_log = []\n",
    "k = []\n",
    "for f in set(tw_trigrams.values()):\n",
    "    Nk_log.append(np.log(len([w for w in tw_trigrams.keys() if tw_trigrams[w] == f])))\n",
    "    k.append(np.log(f))\n",
    "    \n",
    "Nk_log = np.array(Nk_log)\n",
    "k = np.array(k)\n",
    "z = np.polyfit(k, Nk_log, 1)\n",
    "\n",
    "# Calcula tabla de bigramas\n",
    "for v in trigram_list:\n",
    "    if v[0] not in trigram_table:\n",
    "        trigram_table[v[0]] = {}\n",
    "\n",
    "    if v[1] not in trigram_table[v[0]]:\n",
    "        trigram_table[v[0]][v[1]] = {}\n",
    "        \n",
    "    if tw_trigrams[(v[0], v[1], v[2])] > limit or (tw_trigrams[(v[0], v[1], v[2])]+1) not in Nk:\n",
    "        c = power_law(z, tw_trigrams[(v[0], v[1], v[2])]+1)\n",
    "    else:\n",
    "        c = (tw_trigrams[(v[0], v[1], v[2])] + 1)*(Nk[tw_trigrams[(v[0], v[1], v[2])]+1]/Nk[tw_trigrams[(v[0], v[1], v[2])]])\n",
    "\n",
    "    bigram_table[v[0]][v[1], v[2]] = c/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5. Modelo lenguaje con Add-one Smoothing en tweets agresivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ngram():\n",
    "    \n",
    "    def __init__(self, corpus, punct):\n",
    "        self.corpus = corpus\n",
    "        self.punct = punct\n",
    "        \n",
    "        self.unigrams = self.build_ngrams(1)\n",
    "        self.bigrams = self.build_ngrams(2)\n",
    "        self.trigrams = self.build_ngrams(3)\n",
    "        \n",
    "        self.unigram_vocab = set(self.unigrams.keys())\n",
    "        self.bigram_vocab = set(self.bigrams.keys())\n",
    "        self.trigram_vocab = set(self.trigrams.keys())\n",
    "        self.unigram_size = len(self.unigram_vocab)\n",
    "        self.bigram_size = len(self.bigram_vocab)\n",
    "        self.trigram_size = len(self.trigram_vocab)\n",
    "\n",
    "        self.bigrams_table = self.build_bigram_table()\n",
    "        self.trigrams_table = self.build_trigram_table()\n",
    "        \n",
    "    def process_word(self, w):\n",
    "        is_punct = True if w in self.punct else False\n",
    "        is_digit = w.isnumeric()\n",
    "        is_stopword = w in stopwords.words('spanish')\n",
    "\n",
    "        return \"\" if is_punct or is_digit or is_stopword else w.lower()\n",
    "        \n",
    "    def build_ngrams(self, n):\n",
    "        tk = TweetTokenizer()\n",
    "        tokens = [self.process_word(w) for sent in self.corpus for w in tk.tokenize(sent)]\n",
    "        tokens = list(filter(None, tokens))\n",
    "        tw_trigrams = words_to_ngrams(tokens, n)\n",
    "        tw_trigrams = FreqDist(tw_trigrams)\n",
    "\n",
    "        return tw_trigrams\n",
    "    \n",
    "    def build_bigram_table(self):\n",
    "        bigram_table = {}\n",
    "\n",
    "        for v in self.bigram_vocab:\n",
    "            if v[0] not in bigram_table:\n",
    "                bigram_table[v[0]] = {}\n",
    "            bigram_table[v[0]][v[1]] = (self.bigrams[(v[0], v[1])] + 1)/(self.unigrams[v[0]] + self.bigram_size)\n",
    "        \n",
    "        return bigram_table\n",
    "    \n",
    "    def build_trigram_table(self):\n",
    "        trigram_table = {}\n",
    "\n",
    "        for v in self.trigram_vocab:\n",
    "            if v[0] not in trigram_table:\n",
    "                trigram_table[v[0]] = {}\n",
    "\n",
    "            if v[1] not in trigram_table[v[0]]:\n",
    "                trigram_table[v[0]][v[1]] = {}\n",
    "\n",
    "            trigram_table[v[0]][v[1]][v[2]] = (self.trigrams[(v[0], v[1], v[2])] + 1)/(self.bigrams[(v[0], v[1])] + self.trigram_size)\n",
    "        return trigram_table\n",
    "    \n",
    "    def prob_sentence_bigram(self, s):\n",
    "        words_split = s.split()\n",
    "        words = []\n",
    "        for w in words_split:\n",
    "            if w in self.unigram_vocab:\n",
    "                words.append(w)\n",
    "                \n",
    "        if len(words) == 0:\n",
    "            return 0\n",
    "        \n",
    "        prob = 0\n",
    "        prob += np.log(self.unigrams[words[0]]/self.unigram_size)\n",
    "        \n",
    "        if len(words) == 1:\n",
    "            return -prob\n",
    "        elif len(words) == 2:\n",
    "            prob += np.log(self.prob_bigram(words[1], words[0]))\n",
    "            return -prob\n",
    "        \n",
    "        for i in range(1, len(words)-1):\n",
    "            prob += np.log(self.prob_bigram(words[i+1], words[i]))\n",
    "        \n",
    "        return -prob\n",
    "    \n",
    "    def prob_bigram(self, w2, w1):\n",
    "        if w1 in self.bigrams_table and w2 in self.bigrams_table[w1]:\n",
    "            return self.bigrams_table[w1][w2]\n",
    "        else:\n",
    "            return 1/(self.unigrams[w1] + self.bigram_size)\n",
    "        \n",
    "    def prob_sentence_trigram(self, s):\n",
    "        words_split = s.split()\n",
    "        words = []\n",
    "        for w in words_split:\n",
    "            if w in self.unigram_vocab:\n",
    "                words.append(w)\n",
    "                \n",
    "        if len(words) == 0:\n",
    "            return 0\n",
    "        \n",
    "        prob = 0\n",
    "        prob += self.unigrams[words[0]]/self.unigram_size\n",
    "        \n",
    "        if len(words) == 1:\n",
    "            return -prob\n",
    "        elif len(words) == 2:\n",
    "            prob += np.log(self.prob_bigram(words[1], words[0]))\n",
    "            return -prob\n",
    "        elif len(words) == 3:\n",
    "            prob += np.log(self.prob_trigram(words[2], words[0], words[1]))\n",
    "            return -prob\n",
    "        \n",
    "        for i in range(1, len(words)-2):\n",
    "            prob += np.log(self.prob_trigram(words[i+2], words[i], words[i+1]))\n",
    "        \n",
    "        return -prob\n",
    "    \n",
    "    def prob_trigram(self, w3, w1, w2):\n",
    "        if w1 in self.trigrams_table and w2 in self.trigrams_table[w1] and w3 in self.trigrams_table[w1][w2]:\n",
    "            return self.trigrams_table[w1][w2][w3]\n",
    "        else:\n",
    "            return 1/(self.bigrams[(w1, w2)] + self.trigram_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ngram(tweets_agg, punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2884328463463779e-05"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prob_sentence_bigram(\"hijo de puta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.962210844651776e-06"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prob_sentence_bigram(\"de puta hijo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.241810949130512e-06"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prob_sentence_trigram(\"hijo de puta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.643867211531108e-06"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prob_sentence_trigram(\"de puta hijo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios 6 y 7. Perplejidad para modelo de bigramas y trigramas en tweets agresivos de conjunto de datos test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se leen los datos del conjunto test de la clase 1 (agresivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mex_test.txt', 'r') as f:\n",
    "    corpus_test = f.readlines()\n",
    "    \n",
    "with open('mex_test_labels.txt', 'r') as f:\n",
    "    labels_test = f.readlines()\n",
    "\n",
    "labels_test = [int(lab.strip('\\n')) for lab in labels_test]\n",
    "tweets_agg_test = [tw for tw, lab in zip(corpus_test, labels_test) if lab == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_test = \" \".join([s.strip('\\n') for s in tweets_agg_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean los modelos de bigramas y trigramas con el conjunto de training de la clase 1 (agresivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mex_train.txt', 'r') as f:\n",
    "    corpus_train = f.readlines()\n",
    "    \n",
    "with open('mex_train_labels.txt', 'r') as f:\n",
    "    labels_train = f.readlines()\n",
    "\n",
    "labels_train = [int(lab.strip('\\n')) for lab in labels_train]\n",
    "tweets_agg_train = [tw for tw, lab in zip(corpus_train, labels_train) if lab == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ngram(tweets_agg_train, punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se calcula perplejidad del modelo de bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31248.935971169733"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prob_sentence_bigram(sentence_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se calcula perplejidad del modelo de trigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32421.711227860647"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prob_sentence_trigram(sentence_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 8. Modelo combinado (unigramas, bigramas y trigramas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
